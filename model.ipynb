{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape = (7613, 5)\n",
      "Training Set Memory Usage = 0.29 MB\n",
      "Test Set Shape = (3263, 4)\n",
      "Test Set Memory Usage = 0.10 MB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"dataset/train.csv\")\n",
    "df_test = pd.read_csv(\"dataset/test.csv\") # Test dataset has no target, we'll need to do a validation split\n",
    "\n",
    "print('Training Set Shape = {}'.format(df_train.shape))\n",
    "print('Training Set Memory Usage = {:.2f} MB'.format(df_train.memory_usage().sum() / 1024**2))\n",
    "print('Test Set Shape = {}'.format(df_test.shape))\n",
    "print('Test Set Memory Usage = {:.2f} MB'.format(df_test.memory_usage().sum() / 1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_train['text']\n",
    "target = df_train['target']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(text, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# class ElmoEmbeddingLayer(Layer):\n",
    "#     def __init__(self, **kwargs):\n",
    "#         self.dimensions = 1024\n",
    "#         self.trainable = True\n",
    "#         super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "#     def build(self, input_shape):\n",
    "#         self.elmo = tf.compat.v1.Module ('https://tfhub.dev/google/elmo/2', trainable=self.trainable, name=\"{}_module\".format(self.name))\n",
    "#         self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
    "#         super(ElmoEmbeddingLayer, self).build(input_shape)\n",
    "#     def call(self, x, mask=None):\n",
    "#         result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
    "#                       as_dict=True,\n",
    "#                       signature='default',\n",
    "#                       )['default']\n",
    "#         return result\n",
    "#     def compute_mask(self, inputs, mask=None):\n",
    "#         return K.not_equal(inputs, '--PAD--')\n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         return (input_shape[0], self.dimensions)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'elmo_embedding' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `too many positional arguments`. Received args: (<KerasTensor shape=(None, 100), dtype=string, sparse=None, name=keras_tensor_4>,) and kwargs: {} for signature: () -> Dict[['lstm_outputs1', TensorSpec(shape=(None, None, 1024), dtype=tf.float32, name=None)], ['lstm_outputs2', TensorSpec(shape=(None, None, 1024), dtype=tf.float32, name=None)], ['word_emb', TensorSpec(shape=(None, None, 512), dtype=tf.float32, name=None)], ['elmo', TensorSpec(shape=(None, None, 1024), dtype=tf.float32, name=None)], ['sequence_len', TensorSpec(shape=(None,), dtype=tf.int32, name=None)], ['default', TensorSpec(shape=(None, 1024), dtype=tf.float32, name=None)]].\nFallback to flat signature also failed due to: pruned(text): expected argument #0(zero-based) to be a Tensor; got KerasTensor (<KerasTensor shape=(None, 100), dtype=string, sparse=None, name=keras_tensor_4>).\n\nCall arguments received by layer 'elmo_embedding' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None, 100), dtype=string, sparse=None, name=keras_tensor_4>\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     26\u001b[0m input_text \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(max_length,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mstring)\n\u001b[1;32m---> 27\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43melmo\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m dense \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(embedding)\n\u001b[0;32m     30\u001b[0m pred \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)(dense)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\keras_layer.py:242\u001b[0m, in \u001b[0;36mKerasLayer.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# ...but we may also have to pass a Python boolean for `training`, which\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# is the logical \"and\" of this layer's trainability and what the surrounding\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# model is doing (analogous to keras.layers.BatchNormalization in TF2).\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# For the latter, we have to look in two places: the `training` argument,\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_training_argument:\n\u001b[1;32m--> 242\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable:\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling layer 'elmo_embedding' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `too many positional arguments`. Received args: (<KerasTensor shape=(None, 100), dtype=string, sparse=None, name=keras_tensor_4>,) and kwargs: {} for signature: () -> Dict[['lstm_outputs1', TensorSpec(shape=(None, None, 1024), dtype=tf.float32, name=None)], ['lstm_outputs2', TensorSpec(shape=(None, None, 1024), dtype=tf.float32, name=None)], ['word_emb', TensorSpec(shape=(None, None, 512), dtype=tf.float32, name=None)], ['elmo', TensorSpec(shape=(None, None, 1024), dtype=tf.float32, name=None)], ['sequence_len', TensorSpec(shape=(None,), dtype=tf.int32, name=None)], ['default', TensorSpec(shape=(None, 1024), dtype=tf.float32, name=None)]].\nFallback to flat signature also failed due to: pruned(text): expected argument #0(zero-based) to be a Tensor; got KerasTensor (<KerasTensor shape=(None, 100), dtype=string, sparse=None, name=keras_tensor_4>).\n\nCall arguments received by layer 'elmo_embedding' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None, 100), dtype=string, sparse=None, name=keras_tensor_4>\n  • training=None"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.layers import Dropout\n",
    "# from tensorflow.keras.layers import Lambda\n",
    "# from tensorflow.keras.layers import Concatenate\n",
    "# from tensorflow.keras.layers import LSTM\n",
    "# from tensorflow.keras.layers import Bidirectional\n",
    "# from tensorflow.keras.layers import BatchNormalization\n",
    "# from tensorflow.keras.layers import SpatialDropout1D\n",
    "# from tensorflow.keras.layers import Embedding\n",
    "# from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "# from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "max_length = 100\n",
    "\n",
    "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
    "# embedding = ElmoEmbeddingLayer()(input_text)\n",
    "# Create Elmo embedding layer\n",
    "elmo = hub.KerasLayer(\"https://tfhub.dev/google/elmo/3\", trainable=False, name='elmo_embedding')\n",
    "\n",
    "# Example usage\n",
    "input_text = Input(shape=(max_length,), dtype=tf.string)\n",
    "embedding = elmo(input_text)\n",
    "\n",
    "dense = layers.Dense(256, activation='relu')(embedding)\n",
    "pred = layers.Dense(1, activation='sigmoid')(dense)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', \"f1\"])\n",
    "model.summary()\n",
    "# model.fit(X_train, \n",
    "#           y_train,\n",
    "#           validation_data=(X_val, y_val),\n",
    "#           epochs=5,\n",
    "#           batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
